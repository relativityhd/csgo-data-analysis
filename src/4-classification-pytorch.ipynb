{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation mit PyTorch\n",
    "\n",
    "Dieses vierte und letzte Notebook nutzt PyTorch um Neuronale Netze zu entwickeln, welche professionelle Spieler von unprofessionellen trennt. Dazu wird zuerst ein `Torch Dataset` und anschließend ein `PyTorch-Lightning DataModule` erstellt. Dieses kann dann vom `PyTorch-Lightning Module` über den Trainer konsumiert werden. `PyTorch-Lightning` ist ein Wrapper um schnell Neuronale Netze zu implementieren und diese mit diversen Methoden zu trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Dataset\n",
    "\n",
    "Das Dataset basiert auf dem im zweiten Notebook erzeugtem Datensatz in Form eines DataFrames. Aus diesem wird bei der Erstellung des Datasets zuerst für die beiden kategorischen Features `Map` und `Region` ein Label-Encoder implementiert. Darauf werden die encodierten Kategorien zusammen mit den ohnehin schon numerischen Werten zu Numpy-Arrays extrahiert, damit diese später in PyTorch-Tensoren transformiert werden können. Wie in dem letzten Notebook werden lediglich die Attribute `[\"Region\", \"Map\", \"K/R Ratio\", \"K/D Ratio\", \"Premade\", \"Kills\", \"MVPs\", \"Headshots\", \"Triple Kills\"]` extrahiert. Das PyTorch-Lightning Data Module implementiert den Train/Validate/Test-Split mit einer 81/9/10 Ratio. Weiterhin implementiert das Data Module auch den PyTorch DataLoader, welcher die Daten des Datensatzes in Batches einteilt und diese zu Torch-Tensoren umwandelt. Die Trainingsdaten werden dabei zufällig gebatched, die Validierungs- und Testdaten um Vergleichbarkeit beizubehalten nicht zufällig. Um die Daten schneller zu laden werden 12 Worker benutzt, wodurch 11 Batches schon vor Benutzung auf anderen Threads geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsgoProfessionalDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        region_map = {k:v for v, k in enumerate(df[\"Region\"].unique())}\n",
    "        map_map = {k:v for v, k in enumerate(df[\"Map\"].unique())}\n",
    "        self.x = np.array([\n",
    "            np.array([region_map[x] for x in df[\"Region\"]]),\n",
    "            np.array([map_map[x] for x in df[\"Map\"]]),\n",
    "            df[\"K/R Ratio\"].to_numpy(),\n",
    "            df[\"K/D Ratio\"].to_numpy(),\n",
    "            df[\"Premade\"].to_numpy(),\n",
    "            df[\"Kills\"].to_numpy(),\n",
    "            df[\"MVPs\"].to_numpy(),\n",
    "            df[\"Headshots\"].to_numpy(),\n",
    "            df[\"Triple Kills\"].to_numpy()\n",
    "        ], dtype=np.float32)\n",
    "        self.y = df[\"Professional\"].to_numpy(np.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[:, idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "class CsgoProfessionalDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, df: pd.DataFrame, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        fit_test_split = int(len(self.df) * 0.9)\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            ds_full = CsgoProfessionalDataset(self.df[:fit_test_split])\n",
    "            train_len = int(fit_test_split * 0.9)\n",
    "            val_len = fit_test_split - train_len\n",
    "            self.ds_train, self.ds_val = random_split(ds_full, [train_len, val_len])\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.ds_test = CsgoProfessionalDataset(self.df[fit_test_split:])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train, batch_size=self.batch_size, drop_last=True, shuffle=True, num_workers=12)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, batch_size=self.batch_size, drop_last=True, num_workers=12)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.ds_test, batch_size=self.batch_size, drop_last=True, num_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Modell\n",
    "\n",
    "Das PyTorch-Lightning Module implementiert das neuronale Netz sowie die Trainings-Loop. Allgemein wird sich an sämtliche Standards für die Implementierung von PyTorch Modellen mit PyTorch-Lightning gehalten, um so viele Funktionen von Lightning wie möglich nutzen zu können und die Code-Base entsprechend klein, einfach und verständlich zu halten. Dazu ist natürlich entsprechendes Vorwissen über die Funktionsweise des PyTorch-Lightning Frameworks vorausgesetzt. Das Netz hat folgenden Aufbau:\n",
    "\n",
    "- `9` Input-Nodes\n",
    "- `9xN` Gewichte\n",
    "-> `N` Hidden-Nodes\n",
    "- ReLU Aktivierungsfunktion\n",
    "- Dropout\n",
    "-> `N` Hidden-Nodes\n",
    "- `NxN` Gewichte\n",
    "-> `N` Hidden-Nodes\n",
    "- ReLU Aktivierungsfunktion\n",
    "- Dropout\n",
    "-> `N` Hidden-Nodes\n",
    "- `Nx1` Gewichte\n",
    "-> `1` Node\n",
    "- Sigmoid\n",
    "- Threshold `0.5`\n",
    "-> Ergebnis\n",
    "\n",
    "Die Auswahl dieser Architektur geschah willkürlich basierend auf Erfahrung und Ausprobieren.\n",
    "\n",
    "In der Trainigns-Loop wird der `Binary-Cross-Entropy-With-Logits` Verlust berechnet, entsprechend ohne Anwendung der Sigmoid Funktion. Diese ist mathematisch in die Verlustfunktion integriert und muss deshalb nur bei der Inferenz angewendet werden. Das Training optimiert über den Adam-Optimierungsalgorithmus. Zur Validierung wird die Bibliothek `torchmetrics` genutzt, welche die schon im 3. Notebook genutzten Metriken Accuracy, F1Score, Precision und Recall implementiert und auf PyTorch-Lightning besonders angepasst ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsgoProfessionalClassifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, learning_rate: float, hidden_layers: int, dropout: float, loss_weight: float=0.5):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(9, hidden_layers),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_layers, hidden_layers),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_layers, 1)\n",
    "        )\n",
    "        self.loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(loss_weight))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.metrics = torchmetrics.MetricCollection([\n",
    "            #torchmetrics.AUC(),\n",
    "            torchmetrics.Accuracy(),\n",
    "            torchmetrics.F1Score(),\n",
    "            torchmetrics.Precision(),\n",
    "            torchmetrics.Recall()\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze()\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch: List[torch.Tensor], batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: List[torch.Tensor], batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss(logits, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        preds = self.sigmoid(logits)\n",
    "        self.metrics(preds, y.int())\n",
    "        self.log_dict(self.metrics)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter-Optimierung\n",
    "\n",
    "Zur Optimierung der Hyperparameter wird wieder Optuna genutzt. Es werden die drei Hyperparameter:\n",
    "\n",
    "- `hidden_layers` Größe der beiden Hidden-Layer des Netzes\n",
    "- `dropout` Dropout Wahrscheinlichkeit beim Training\n",
    "- `learning_rate` Lernrate beim Training\n",
    "\n",
    "Ein Training ist recht Rechenaufwendig, weshalb zum einen lediglich ein Subset des Datensatzes über maximal 20 Epochen trainiert wird und weiterhin Pruning eingesetzt wird, also verfrühtes stoppen eines Trainings sollte dies weniger schnell oder gut konvergieren als vorherige. Die Batch-Größe ist immer 32.\n",
    "\n",
    "PyTorch-Lightning Loggs dabei die Metriken in den `lightning_logs` Ordner mit TensorBoard. Die Metriken können live während dem Training über TensorBoard angeschaut werden:\n",
    "\n",
    "```sh\n",
    "$ pwd\n",
    "/path/to/this/repo # ! Not /path/to/this/repo/src\n",
    "# Wenn Poetry zur Installation genutzt wurde, aber jedes Environment mit TensorBoard geht auch\n",
    "$ poetry shell\n",
    "\n",
    "$ tensorboard --logdir ./src/lightning_logs\n",
    "```\n",
    "\n",
    "Über Tensorboard ist es entsprechend auch möglich, die Auswirkungen verschiedener Hyperparemeter auszuwerten.\n",
    "\n",
    "> In der Abgabe ist bereits der Ordner `lightning_logs` mit den entsprechenden Logs vom durchgeführtem Training enthalten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_feather(\"../data/2-player_match_statistics_cleaned.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-25 12:56:12,135]\u001b[0m A new study created in memory with name: no-name-748f8c0f-aeca-4856-bcd4-2139469e319f\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:56:42,946]\u001b[0m Trial 0 finished with value: 0.47925034165382385 and parameters: {'hidden_layers': 340, 'dropout': 0.4571817581154333, 'learning_rate': 2.223946104391299e-05}. Best is trial 0 with value: 0.47925034165382385.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:57:11,608]\u001b[0m Trial 1 finished with value: 0.5509989261627197 and parameters: {'hidden_layers': 280, 'dropout': 0.3424809876181723, 'learning_rate': 2.1007868345622564e-06}. Best is trial 1 with value: 0.5509989261627197.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:57:40,176]\u001b[0m Trial 2 finished with value: 0.5603113174438477 and parameters: {'hidden_layers': 580, 'dropout': 0.053043236679195915, 'learning_rate': 1.009150271337023e-07}. Best is trial 2 with value: 0.5603113174438477.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:58:09,090]\u001b[0m Trial 3 finished with value: 0.5536062717437744 and parameters: {'hidden_layers': 310, 'dropout': 0.4166026719836675, 'learning_rate': 4.735133621631637e-06}. Best is trial 2 with value: 0.5603113174438477.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:58:38,334]\u001b[0m Trial 4 finished with value: 0.48143985867500305 and parameters: {'hidden_layers': 100, 'dropout': 0.31884920010001727, 'learning_rate': 1.0972995903331445e-06}. Best is trial 2 with value: 0.5603113174438477.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:58:47,446]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:58:56,434]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:59:09,843]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 8.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:59:18,789]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 12:59:48,384]\u001b[0m Trial 9 finished with value: 0.556745171546936 and parameters: {'hidden_layers': 540, 'dropout': 0.24574823607802626, 'learning_rate': 1.718344750617885e-05}. Best is trial 2 with value: 0.5603113174438477.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:00:28,920]\u001b[0m Trial 10 finished with value: 0.5520263314247131 and parameters: {'hidden_layers': 940, 'dropout': 0.0015162525967938878, 'learning_rate': 1.336025391795805e-07}. Best is trial 2 with value: 0.5603113174438477.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:00:38,018]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:01:07,112]\u001b[0m Trial 12 finished with value: 0.4849397540092468 and parameters: {'hidden_layers': 750, 'dropout': 0.18688292654725777, 'learning_rate': 6.902864843406065e-06}. Best is trial 2 with value: 0.5603113174438477.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:01:36,802]\u001b[0m Trial 13 finished with value: 0.596707820892334 and parameters: {'hidden_layers': 440, 'dropout': 0.1789129615245975, 'learning_rate': 1.001735920842319e-05}. Best is trial 13 with value: 0.596707820892334.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:02:06,993]\u001b[0m Trial 14 finished with value: 0.5490196347236633 and parameters: {'hidden_layers': 440, 'dropout': 0.08588126679885472, 'learning_rate': 4.2405336606295733e-07}. Best is trial 13 with value: 0.596707820892334.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:02:36,256]\u001b[0m Trial 15 finished with value: 0.5720250010490417 and parameters: {'hidden_layers': 730, 'dropout': 0.02144158423935777, 'learning_rate': 8.066791477718407e-06}. Best is trial 13 with value: 0.596707820892334.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:02:52,639]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:03:01,985]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:03:32,199]\u001b[0m Trial 18 finished with value: 0.49243468046188354 and parameters: {'hidden_layers': 850, 'dropout': 0.22520689079813652, 'learning_rate': 1.52582248194651e-05}. Best is trial 13 with value: 0.596707820892334.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:03:41,638]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:04:12,370]\u001b[0m Trial 20 finished with value: 0.5454545617103577 and parameters: {'hidden_layers': 440, 'dropout': 0.18450880680638698, 'learning_rate': 3.4601251847649093e-06}. Best is trial 13 with value: 0.596707820892334.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:04:45,168]\u001b[0m Trial 21 finished with value: 0.5695067048072815 and parameters: {'hidden_layers': 630, 'dropout': 0.04592024541340908, 'learning_rate': 9.713089742754589e-06}. Best is trial 13 with value: 0.596707820892334.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:05:15,541]\u001b[0m Trial 22 finished with value: 0.5521191358566284 and parameters: {'hidden_layers': 430, 'dropout': 0.04442457519649185, 'learning_rate': 9.165079785459102e-06}. Best is trial 13 with value: 0.596707820892334.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:05:45,589]\u001b[0m Trial 23 finished with value: 0.598739504814148 and parameters: {'hidden_layers': 650, 'dropout': 0.11177468732734488, 'learning_rate': 3.8398501413668467e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:05:54,929]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:06:24,988]\u001b[0m Trial 25 finished with value: 0.5765765905380249 and parameters: {'hidden_layers': 650, 'dropout': 0.2038130887383188, 'learning_rate': 8.388276252681793e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:06:54,835]\u001b[0m Trial 26 finished with value: 0.5443499088287354 and parameters: {'hidden_layers': 480, 'dropout': 0.20223748250845602, 'learning_rate': 9.302803091426235e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:07:24,746]\u001b[0m Trial 27 finished with value: 0.5738916397094727 and parameters: {'hidden_layers': 660, 'dropout': 0.24710825321928245, 'learning_rate': 6.0543287042603146e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:07:54,716]\u001b[0m Trial 28 finished with value: 0.5150214433670044 and parameters: {'hidden_layers': 860, 'dropout': 0.2829372314719725, 'learning_rate': 2.8711525334106806e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:08:04,106]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:08:34,304]\u001b[0m Trial 30 finished with value: 0.5524402856826782 and parameters: {'hidden_layers': 10, 'dropout': 0.1588953259863999, 'learning_rate': 7.342165292914397e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:09:04,768]\u001b[0m Trial 31 finished with value: 0.5606229305267334 and parameters: {'hidden_layers': 650, 'dropout': 0.2627202710593276, 'learning_rate': 5.4921001842553086e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:11:26,969]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 14.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:11:55,863]\u001b[0m Trial 33 finished with value: 0.5404788851737976 and parameters: {'hidden_layers': 500, 'dropout': 0.12401966674148783, 'learning_rate': 1.2603883193611769e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:12:04,724]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:12:33,694]\u001b[0m Trial 35 finished with value: 0.5675057172775269 and parameters: {'hidden_layers': 260, 'dropout': 0.17602538019553243, 'learning_rate': 2.250380264599563e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:13:02,945]\u001b[0m Trial 36 finished with value: 0.44062498211860657 and parameters: {'hidden_layers': 700, 'dropout': 0.35631742249418463, 'learning_rate': 5.5207840974821074e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:13:11,851]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:13:40,346]\u001b[0m Trial 38 finished with value: 0.5722891092300415 and parameters: {'hidden_layers': 520, 'dropout': 0.09134250274431896, 'learning_rate': 9.309818541648687e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:14:08,785]\u001b[0m Trial 39 finished with value: 0.5403587222099304 and parameters: {'hidden_layers': 830, 'dropout': 0.2753743259763842, 'learning_rate': 2.3291405926928292e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:14:37,831]\u001b[0m Trial 40 finished with value: 0.4878048896789551 and parameters: {'hidden_layers': 260, 'dropout': 0.2315498544132989, 'learning_rate': 4.257892411409944e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:15:06,325]\u001b[0m Trial 41 finished with value: 0.5656566023826599 and parameters: {'hidden_layers': 530, 'dropout': 0.08957255922038562, 'learning_rate': 8.384332437299483e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:15:35,163]\u001b[0m Trial 42 finished with value: 0.5818882584571838 and parameters: {'hidden_layers': 560, 'dropout': 0.13917268619953393, 'learning_rate': 9.803169082366589e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:16:03,228]\u001b[0m Trial 43 finished with value: 0.48951050639152527 and parameters: {'hidden_layers': 580, 'dropout': 0.13905401560165795, 'learning_rate': 6.339953444678034e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:16:31,326]\u001b[0m Trial 44 finished with value: 0.5666666626930237 and parameters: {'hidden_layers': 700, 'dropout': 0.3142266187795337, 'learning_rate': 3.531822581909572e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:16:59,298]\u001b[0m Trial 45 finished with value: 0.5387453436851501 and parameters: {'hidden_layers': 610, 'dropout': 0.16888646426776716, 'learning_rate': 5.3340077264701663e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:17:27,943]\u001b[0m Trial 46 finished with value: 0.5282050967216492 and parameters: {'hidden_layers': 320, 'dropout': 0.20055442151670527, 'learning_rate': 9.850594715079561e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:17:56,567]\u001b[0m Trial 47 finished with value: 0.47390687465667725 and parameters: {'hidden_layers': 460, 'dropout': 0.4560272301388707, 'learning_rate': 1.4153455986684446e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:18:24,673]\u001b[0m Trial 48 finished with value: 0.5462273955345154 and parameters: {'hidden_layers': 550, 'dropout': 0.06454786835445696, 'learning_rate': 9.26880046566528e-07}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:18:52,659]\u001b[0m Trial 49 finished with value: 0.5856980681419373 and parameters: {'hidden_layers': 680, 'dropout': 0.13434615711595332, 'learning_rate': 1.7930703979645048e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:19:21,005]\u001b[0m Trial 50 finished with value: 0.5682326555252075 and parameters: {'hidden_layers': 800, 'dropout': 0.11023843923346538, 'learning_rate': 1.9757427007994306e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:19:49,474]\u001b[0m Trial 51 finished with value: 0.3572743833065033 and parameters: {'hidden_layers': 680, 'dropout': 0.1408867300522636, 'learning_rate': 2.8725292706097726e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:20:17,738]\u001b[0m Trial 52 finished with value: 0.5178571939468384 and parameters: {'hidden_layers': 740, 'dropout': 0.18706935570608238, 'learning_rate': 5.906021257473258e-06}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:20:26,512]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:20:35,111]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:20:44,031]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:21:12,604]\u001b[0m Trial 56 finished with value: 0.5687302947044373 and parameters: {'hidden_layers': 410, 'dropout': 0.10152674426333344, 'learning_rate': 2.2631941892614183e-06}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:21:41,099]\u001b[0m Trial 57 finished with value: 0.5601800084114075 and parameters: {'hidden_layers': 750, 'dropout': 0.21134215988408445, 'learning_rate': 1.7596606088633223e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:22:10,054]\u001b[0m Trial 58 finished with value: 0.5620512962341309 and parameters: {'hidden_layers': 490, 'dropout': 0.15664393618399358, 'learning_rate': 5.05665585264328e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:22:38,625]\u001b[0m Trial 59 finished with value: 0.5343136787414551 and parameters: {'hidden_layers': 880, 'dropout': 0.1885647311816744, 'learning_rate': 3.112982554511657e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:22:47,589]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:23:16,178]\u001b[0m Trial 61 finished with value: 0.5739514827728271 and parameters: {'hidden_layers': 530, 'dropout': 0.0944588507629778, 'learning_rate': 9.963905521348483e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:24:26,211]\u001b[0m Trial 62 finished with value: 0.5504152178764343 and parameters: {'hidden_layers': 630, 'dropout': 0.12163912392994246, 'learning_rate': 7.299804706108964e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:24:54,687]\u001b[0m Trial 63 finished with value: 0.4314381182193756 and parameters: {'hidden_layers': 550, 'dropout': 0.022468497261741466, 'learning_rate': 9.932269397412917e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:25:03,479]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:25:32,138]\u001b[0m Trial 65 finished with value: 0.5382775068283081 and parameters: {'hidden_layers': 510, 'dropout': 0.058435891870361384, 'learning_rate': 4.231868610188212e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:25:40,876]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:26:09,767]\u001b[0m Trial 67 finished with value: 0.549835741519928 and parameters: {'hidden_layers': 390, 'dropout': 0.14730008214855297, 'learning_rate': 7.835825253975736e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:26:18,840]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:26:47,553]\u001b[0m Trial 69 finished with value: 0.5494737029075623 and parameters: {'hidden_layers': 780, 'dropout': 0.03185611691262985, 'learning_rate': 6.562605664040509e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:27:05,060]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 11.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:27:13,960]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:27:42,639]\u001b[0m Trial 72 finished with value: 0.5803758502006531 and parameters: {'hidden_layers': 580, 'dropout': 0.10573343314376416, 'learning_rate': 4.8102273447877515e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:28:11,458]\u001b[0m Trial 73 finished with value: 0.5372781157493591 and parameters: {'hidden_layers': 590, 'dropout': 0.10250196132819767, 'learning_rate': 4.840037019099546e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:28:48,682]\u001b[0m Trial 74 finished with value: 0.5541125535964966 and parameters: {'hidden_layers': 630, 'dropout': 0.1770751863266218, 'learning_rate': 3.423673603392412e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:29:18,337]\u001b[0m Trial 75 finished with value: 0.556291401386261 and parameters: {'hidden_layers': 570, 'dropout': 0.15616501046898096, 'learning_rate': 2.786591778133049e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:29:46,876]\u001b[0m Trial 76 finished with value: 0.507317066192627 and parameters: {'hidden_layers': 470, 'dropout': 0.1329637401674105, 'learning_rate': 6.102252679275983e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:30:15,334]\u001b[0m Trial 77 finished with value: 0.5610034465789795 and parameters: {'hidden_layers': 680, 'dropout': 0.10997628674731105, 'learning_rate': 4.517237891750689e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:30:43,940]\u001b[0m Trial 78 finished with value: 0.5404813885688782 and parameters: {'hidden_layers': 420, 'dropout': 0.22044157732464215, 'learning_rate': 7.683351617189355e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:31:12,385]\u001b[0m Trial 79 finished with value: 0.5178571939468384 and parameters: {'hidden_layers': 610, 'dropout': 0.19762621935649485, 'learning_rate': 6.722730118671288e-06}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:31:43,220]\u001b[0m Trial 80 finished with value: 0.521261990070343 and parameters: {'hidden_layers': 540, 'dropout': 0.0724323232971073, 'learning_rate': 1.6905704395396065e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:32:11,071]\u001b[0m Trial 81 finished with value: 0.5376593470573425 and parameters: {'hidden_layers': 510, 'dropout': 0.04897235765632798, 'learning_rate': 8.74674522552268e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:32:38,787]\u001b[0m Trial 82 finished with value: 0.4849279224872589 and parameters: {'hidden_layers': 340, 'dropout': 0.08280267385143483, 'learning_rate': 5.896110193887417e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:33:06,448]\u001b[0m Trial 83 finished with value: 0.5518814325332642 and parameters: {'hidden_layers': 640, 'dropout': 0.11498286116326906, 'learning_rate': 9.902527522768975e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:33:34,041]\u001b[0m Trial 84 finished with value: 0.5498782992362976 and parameters: {'hidden_layers': 580, 'dropout': 0.08972280593415503, 'learning_rate': 7.546383369504839e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:33:45,176]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 7.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:34:12,550]\u001b[0m Trial 86 finished with value: 0.4892703592777252 and parameters: {'hidden_layers': 530, 'dropout': 0.17056698643402057, 'learning_rate': 4.7927254595092015e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:34:40,125]\u001b[0m Trial 87 finished with value: 0.5619146823883057 and parameters: {'hidden_layers': 440, 'dropout': 0.26385559964533023, 'learning_rate': 2.4330815191844755e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:35:07,516]\u001b[0m Trial 88 finished with value: 0.5905511975288391 and parameters: {'hidden_layers': 670, 'dropout': 0.09942931749015849, 'learning_rate': 8.138649433142183e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:35:34,957]\u001b[0m Trial 89 finished with value: 0.5301507115364075 and parameters: {'hidden_layers': 670, 'dropout': 0.12066717273552592, 'learning_rate': 3.198182753784851e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:36:02,508]\u001b[0m Trial 90 finished with value: 0.5404101014137268 and parameters: {'hidden_layers': 810, 'dropout': 0.16077406987056803, 'learning_rate': 6.759218102004203e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:36:30,014]\u001b[0m Trial 91 finished with value: 0.5502008199691772 and parameters: {'hidden_layers': 610, 'dropout': 0.09944599930364638, 'learning_rate': 9.217924103637876e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:36:57,682]\u001b[0m Trial 92 finished with value: 0.5849639773368835 and parameters: {'hidden_layers': 490, 'dropout': 0.06532749161190372, 'learning_rate': 8.179702396388604e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:38:25,542]\u001b[0m Trial 93 finished with value: 0.40071552991867065 and parameters: {'hidden_layers': 760, 'dropout': 0.13222334580441195, 'learning_rate': 5.464972603309419e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:38:53,075]\u001b[0m Trial 94 finished with value: 0.4928774833679199 and parameters: {'hidden_layers': 490, 'dropout': 0.05656274221763252, 'learning_rate': 8.15585458015592e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:39:20,647]\u001b[0m Trial 95 finished with value: 0.5779092311859131 and parameters: {'hidden_layers': 570, 'dropout': 0.06685968322763544, 'learning_rate': 3.842267004422402e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:39:48,045]\u001b[0m Trial 96 finished with value: 0.46203553676605225 and parameters: {'hidden_layers': 560, 'dropout': 0.06264314962156849, 'learning_rate': 4.056902850474906e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:39:56,507]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:40:24,223]\u001b[0m Trial 98 finished with value: 0.5517241954803467 and parameters: {'hidden_layers': 470, 'dropout': 0.07196747004312941, 'learning_rate': 3.0851977474750484e-06}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n",
      "\u001b[32m[I 2022-07-25 13:40:51,738]\u001b[0m Trial 99 finished with value: 0.5326876044273376 and parameters: {'hidden_layers': 400, 'dropout': 0.11346580914335316, 'learning_rate': 4.9230043583438516e-05}. Best is trial 23 with value: 0.598739504814148.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.598739504814148\n",
      "  Params: \n",
      "    hidden_layers: 650\n",
      "    dropout: 0.11177468732734488\n",
      "    learning_rate: 3.8398501413668467e-05\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Get the bias of the dataset to adjust the loss with a weight see https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
    "_, counts = np.unique(df[\"Professional\"], return_counts=True)\n",
    "dataset_bias = counts[0] / counts[1]\n",
    "\n",
    "# configure logging at the root level of Lightning\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "def objective(trial: optuna.Trial):\n",
    "    # Getting Hyperparameter\n",
    "    hidden_layers = trial.suggest_int(\"hidden_layers\", 10, 1000, step=10)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-7, 1e-4, log=True)\n",
    "    # For the right logging of hyperparameter\n",
    "    hyperparameters = dict(hidden_layers=hidden_layers, dropout=dropout, learning_rate=learning_rate)\n",
    "\n",
    "    # Instanciate DataModule and Model\n",
    "    subset_df = df[:10000]\n",
    "    dm = CsgoProfessionalDataModule(subset_df, 32)\n",
    "    model = CsgoProfessionalClassifier(learning_rate, hidden_layers, dropout, loss_weight=dataset_bias)\n",
    "\n",
    "    # Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        logger=True,\n",
    "        enable_checkpointing=False,\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        gpus=1 if torch.cuda.is_available() else None,\n",
    "        enable_progress_bar = False,\n",
    "        enable_model_summary=False,\n",
    "        callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"F1Score\")],\n",
    "    )\n",
    "    trainer.logger.log_hyperparams(hyperparameters)\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    return trainer.callback_metrics[\"F1Score\"].item()\n",
    "\n",
    "# Don't Prune in the first 5 epochs\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=100, timeout=5*60*60)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "\n",
    "# configure logging at the root level of Lightning\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finales Training\n",
    "\n",
    "Schlussendlich wird das neuronale Netz auf den kompletten Datensatz über 200 Epochen mit der optimelen Kombination an Hyperparametern trainiert. Die Validierungs-Metriken werden wie im 3. Notebook auch in einen DataFrame gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | layers  | Sequential        | 430 K \n",
      "1 | loss    | BCEWithLogitsLoss | 0     \n",
      "2 | sigmoid | Sigmoid           | 0     \n",
      "3 | metrics | MetricCollection  | 0     \n",
      "----------------------------------------------\n",
      "430 K     Trainable params\n",
      "0         Non-trainable params\n",
      "430 K     Total params\n",
      "1.721     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': tensor(0.6690),\n",
       " 'val_loss': tensor(0.7543),\n",
       " 'Accuracy': tensor(0.6517),\n",
       " 'F1Score': tensor(0.5812),\n",
       " 'Precision': tensor(0.5464),\n",
       " 'Recall': tensor(0.6208)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layers = study.best_params[\"hidden_layers\"]\n",
    "dropout = study.best_params[\"dropout\"]\n",
    "learning_rate = study.best_params[\"learning_rate\"]\n",
    "\n",
    "dm = CsgoProfessionalDataModule(df, 32)\n",
    "model = CsgoProfessionalClassifier(learning_rate, hidden_layers, dropout, loss_weight=dataset_bias)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=True,\n",
    "    enable_checkpointing=True,\n",
    "    max_epochs=200,\n",
    "    gpus=1 if torch.cuda.is_available() else None,\n",
    ")\n",
    "hyperparameters = dict(hidden_layers=hidden_layers, dropout=dropout, learning_rate=learning_rate)\n",
    "trainer.logger.log_hyperparams(hyperparameters)\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.fit(model, datamodule=dm)\n",
    "duration = time.time() - start_time\n",
    "trainer.callback_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = []\n",
    "training_results.append({\"Method\": \"Neural Net\", \"Metric\": \"Precision\", \"Value\": trainer.callback_metrics[\"Precision\"].item()})\n",
    "training_results.append({\"Method\": \"Neural Net\", \"Metric\": \"Recall\", \"Value\": trainer.callback_metrics[\"Recall\"].item()})\n",
    "training_results.append({\"Method\": \"Neural Net\", \"Metric\": \"F1\", \"Value\": trainer.callback_metrics[\"F1Score\"].item()})\n",
    "training_results.append({\"Method\": \"Neural Net\", \"Metric\": \"Accuracy\", \"Value\": trainer.callback_metrics[\"Accuracy\"].item()})\n",
    "training_results.append({\"Method\": \"Neural Net\", \"Metric\": \"Duration\", \"Value\": duration})\n",
    "nn_df = pd.DataFrame(training_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation & Vergleich\n",
    "\n",
    "Zuerst werden die beiden Ergebnis-DataFrames aus dem 3. und diesem Notebook zusammengefügt. Darauf hin werden die 5 Modelle über die 4 Metriken gegenübergestellt. Es zeigt sich, dass die SVM im Vergleich besonders schlecht im Vergleich abschneidet, dabei besonders wenig (<40%) professionelle Spieler erkennt (underfitting). Das Perceptron erkennt mit abspant am meisten (<80%) der professionellen Spieler im Datensatz, ordnet wie die etwas geringere Precision zeigt jedoch häufig auch Spieler fälschlicherweiße den professionellen zu (overfitting). Das neuronale Netz schneidet insgesamt am besten ab: Es overfittet und underfittet nicht stark und weißt höheren Recall und Precision und somit auch F1 Werte auf als die Logistic und Ridge Classifier sowie die SVM.\n",
    "\n",
    "Darauf wird die Trainingszeit der Modelle gegenübergestellt, es ist die logarithmische Skala zu beachten: SVM und das neuronale Netz benötigen einen enorm großen Trainingsaufwand, am schnellsten trainiert der Ridge Classifier.\n",
    "\n",
    "**Bezieht man sich somit auf sowohl die Effektivität als auch die Effizient der Modelle so schneidet das Perceptron mit seiner recht geringen Trainingszeit, geringen Komplexität und trotzdem sehr guten Ergebnisse am besten ab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_df: pd.DataFrame = pd.read_feather(\"../data/3-test-results-sklearn.feather\")\n",
    "viz_df = pd.concat([viz_df, nn_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Metric', ylabel='Value'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=viz_df[viz_df[\"Metric\"] != \"Duration\"], x=\"Metric\", y=\"Value\", hue=\"Method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Metric', ylabel='Value'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=viz_df[viz_df[\"Metric\"] == \"Duration\"], x=\"Metric\", y=\"Value\", hue=\"Method\", log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('csgo-data-analysis-RAygu18h-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07048d6bb5e5d862ed779752ffdca571d1088506dea3a367b4c3c3029cbc5825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
